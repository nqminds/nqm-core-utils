{"version":3,"sources":["webpack:///webpack/universalModuleDefinition","webpack:///webpack/bootstrap 9a7fbb60ee40277db863","webpack:///./src/constants.js","webpack:///external {\"commonjs\":\"lodash\",\"commonjs2\":\"lodash\",\"amd\":\"_\",\"root\":\"_\"}","webpack:///./src/debug.js","webpack:///./src/build-data-key.js","webpack:///./src/databot-utils.js","webpack:///./src/flatten.js","webpack:///./src/resource-utils.js","webpack:///./src/schema-utils.js","webpack:///./src/short-hash.js","webpack:///./src/index.js","webpack:///external \"bluebird\"","webpack:///external \"mongo-parse\""],"names":[],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD,O;ACVA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA,mDAA2C,cAAc;;AAEzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAK;AACL;AACA;;AAEA;AACA;AACA;AACA,mCAA2B,0BAA0B,EAAE;AACvD,yCAAiC,eAAe;AAChD;AACA;AACA;;AAEA;AACA,8DAAsD,+DAA+D;;AAErH;AACA;;AAEA;AACA;;;;;;;;AChEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;;;;;;ACzJA,+C;;;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;;;;;;;;;;;;;ACRA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,GAAG;;AAEH;AACA;;AAEA;;;;;;;;;AC1BA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,oBAAoB,OAAO;AAC3B;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;;;;;;;;AC1BA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,Y;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;;;;;;;;;;;;AChDA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,4BAA4B,UAAU,GAAG,YAAY;AACrD;AACA;AACA,SAAS,gBAAgB,MAAM,UAAU,GAAG,aAAa;AACzD;AACA;AACA;;AAEA;AACA;AACA;AACA,uBAAuB,iBAAiB;AACxC,OAAO;AACP;AACA,OAAO;AACP,yE;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA,uBAAuB,UAAU;AACjC,OAAO;AACP,uBAAuB,SAAS;AAChC;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA,mC;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,OAAO;AACP;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP,6BAA6B,eAAe;AAC5C;AACA;AACA;AACA,OAAO;AACP,uBAAuB;AACvB,OAAO;AACP;AACA;AACA,KAAK;;AAEL;AACA,GAAG;AACH,YAAY;AACZ,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL,wDAAwD;AACxD;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA,uBAAuB;AACvB,SAAS;AACT;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,oEAAoE,gCAAgC;AACpG;AACA;AACA;AACA,KAAK;AACL,mBAAmB;AACnB;AACA,GAAG;;AAEH;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,SAAS,wBAAwB;AACjC;AACA;AACA;AACA;AACA,MAAM,yBAAyB,KAAK;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU,mBAAmB,GAAG,iBAAiB,OAAO,sBAAsB;AAC9E;AACA;AACA;AACA,QAAQ,wBAAwB,GAAG,gBAAgB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,mC;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA;;;;;;;;;ACjRA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,gBAAgB,gBAAgB;AAChC;AACA;AACA,qBAAqB;AACrB;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,+BAA+B,QAAQ;AACvC;AACA,E;;AAEA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACpEA;AACA;AACA;AACA;AACA;AACA;;AAEA,wC;AACA;AACA,mDAAmD,IAAI;AACvD;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,gCAAgC,6CAA6C;;AAE7E;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,kDAAkD,KAAK;AACvD;;AAEA;AACA;AACA;;AAEA;AACA;;+DAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACzEA,gD;;;;;;ACAA,gD","file":"nqm-core-utils.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory(require(\"lodash\"), require(\"bluebird\"), require(\"mongo-parse\"));\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine(\"nqm-core-utils\", [\"_\", \"bluebird\", \"mongo-parse\"], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"nqm-core-utils\"] = factory(require(\"lodash\"), require(\"bluebird\"), require(\"mongo-parse\"));\n\telse\n\t\troot[\"nqm-core-utils\"] = factory(root[\"_\"], root[\"bluebird\"], root[\"mongo-parse\"]);\n})(this, function(__WEBPACK_EXTERNAL_MODULE_1__, __WEBPACK_EXTERNAL_MODULE_10__, __WEBPACK_EXTERNAL_MODULE_11__) {\nreturn \n\n\n// WEBPACK FOOTER //\n// webpack/universalModuleDefinition"," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// identity function for calling harmony imports with the correct context\n \t__webpack_require__.i = function(value) { return value; };\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, {\n \t\t\t\tconfigurable: false,\n \t\t\t\tenumerable: true,\n \t\t\t\tget: getter\n \t\t\t});\n \t\t}\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 9);\n\n\n\n// WEBPACK FOOTER //\n// webpack/bootstrap 9a7fbb60ee40277db863","export default {\n  // Resource access types\n  readAccess:  \"r\",\n  writeAccess: \"w\",\n  executeAccess: \"x\",\n\n  // Share modes\n  publicRWShareMode: \"pw\",    // public read and write\n  publicROShareMode: \"pr\",    // public read, trusted write\n  trustedShareMode:  \"tr\",    // trusted only\n\n  // Event types\n  resourceEventType: \"Resource\",\n  accountEventType:  \"Account\",\n\n  mongooseTypes: {\n    \"string\": 1,\n    \"number\": 1,\n    \"date\": 1,\n    \"boolean\": 1,\n  },\n\n  // Resource types (schema ids)\n  rootGroupResourceType:               \"rootGroup\",\n  schemaResourceType:                  \"schema\",\n  datasetResourceType:                 \"dataset\",\n  visualisationResourceType:           \"visualisation\",\n  groupResourceType:                   \"resourceGroup\",\n  rawFileResourceType:                 \"rawFile\",\n  vocabularyResourceType:              \"vocabulary\",\n  widgetVisualisationResourceType:     \"widgetVisualisation\",\n  timeSeriesVisualisationResourceType: \"timeSeriesVisualisation\",\n  mapVisualisationResourceType:        \"mapVisualisation\",\n  statusVisualisationResourceType:     \"statusVisualisation\",\n  databotBaseType:                     \"databot\",                   // base of all things 'databot'\n  databotResourceType:                 \"databotDefinition\",         // a databot definition\n  databotInstancesResourceType:        \"databotInstances\",          // system resource storing details of running databot instances\n  databotInstanceOutputResourceType:   \"databotInstanceOutput\",     // system resource storing databot instance output\n  databotProcessesResourceType:        \"databotProcesses\",          // system resource storing databot process info\n  activeDatabotHostsResourceType:      \"activeDatabotHosts\",        // system resource storing details of active databot hosts\n  databotHostResourceType:             \"databotHost\",               // system resources that mirror hostAccountType accounts to enable sharing\n  databotGroupResourceType:            \"databotGroup\",\n  databotHostGroupResourceType:        \"databotHostGroup\",\n  databotControllerResourceType:       \"databotController\",\n  datasetFilterResourceType:           \"datasetFilter\",\n  applicationBaseType:                 \"applicationBase\",\n  applicationResourceType:             \"application\",\n  applicationGroupResourceType:        \"applicationGroup\",\n  applicationDataGroupResourceType:    \"applicationDataGroup\",\n  scratchGroupResourceType:            \"scratchGroup\",\n  rootResourceGroupResourceType:       \"rootResourceGroup\",\n  geojsonResourceType:                 \"geojson\",\n\n  // Account types\n  userAccountType:  \"user\",\n  tokenAccountType: \"token\",\n  hostAccountType: \"host\",\n  applicationAccountType: \"application\",\n\n  // Default schema resource\n  schemasResourceId: \"__schemas__\",\n\n  // Default vocabulary resource\n  vocabularyResourceId: \"__vocab__\",\n\n  // Databot stuff.\n  npmDatabotType: \"npm\",\n  inlineDatabotType: \"script\",\n  zipDatabotType: \"zip\",\n  githubDatabotType: \"github\",\n  urlDatabotType: \"url\",\n\n  browserHostType: \"browser\",\n  serverHostType:  \"server\",\n\n  databotInstancesResourceId:      \"__databotInstances__\",\n  databotInstanceOutputResourceId: \"__databotInstanceOutput__\",\n  databotProcessesResourceId:      \"__databotProcesses__\",\n  activeDatabotHostsResourceId:    \"__activeDatabotHosts__\",\n\n  unallocatedDatabotStatus: \"unallocated\",\n  pendingDatabotStatus:     \"pending\",\n  installingDatabotStatus:  \"installing\",\n  partRunningDatabotStatus: \"partRunning\",\n  runningDatabotStatus:     \"running\",\n  pausedDatabotStatus:      \"paused\",\n  stoppingDatabotStatus:    \"stopping\",\n  completeDatabotStatus:    \"complete\",\n  errorDatabotStatus:       \"error\",\n\n  immediateDatabotInstanceRunMode: \"run-now\",\n  alwaysDatabotInstanceRunMode:    \"run-always\",\n  scheduledDatabotInstanceRunMode: \"scheduled\",\n\n  // Privileged databots\n  datasetImportDatabot:     \"__datasetImport__\",\n  datasetCopyDatabot:       \"__datasetCopy__\",\n\n  onlineHostStatus:  \"online\",\n  offlineHostStatus: \"offline\",\n  idleHostStatus:    \"idle\",\n  busyHostStatus:    \"busy\",\n  errorHostStatus:   \"error\",\n\n  resourceVocabularyId:          \"ResourceId\",\n  datasetVocabularyId:           \"DatasetId\",\n  folderVocabularyId:            \"FolderId\",\n  rawFileVocabularyId:           \"RawFileId\",\n  visualisationVocabularyId:     \"VisualisationId\",\n  schemaVocabularyId:            \"SchemaId\",\n  databotDefinitionVocabularyId: \"DatabotDefinitionId\",\n  urlVocabularyId:               \"Url\",\n\n  // Index status\n  builtIndexStatus:      \"built\",\n  pendingIndexStatus:    \"pending\",\n  suspendingIndexStatus: \"suspending\",\n  suspendedIndexStatus:  \"suspended\",\n  errorIndexStatus:      \"error\",\n\n  // Authentication services\n  googleAuthService:     \"oauth:google\",\n  localAuthService:      \"local\",\n\n  // Misc\n  guestAccount: \"...guest...\",\n  maxTimestamp: 8640000000000000,\n  datasetStorePrefix: \"dataset.\",\n\n  // Special folders\n  rootFolderPrefix: \"r.\",\n  rootFolderName: \"root\",\n\n  scratchFolderPrefix: \"s.\",\n  scratchFolderName: \"scratch\",\n  scratchFolderAlias: \"__scratch__\",      // Used in code to refer to the current users scratch folder.\n\n  resourceFolderPrefix: \"rs.\",\n  resourceFolderName: \"resources\",\n\n  applicationFolderPrefix: \"a.\",\n  applicationFolderName: \"applications\",\n\n  applicationDataFolderPrefix: \"ad.\",\n  applicationDataFolderName: \"application data\",\n\n  databotFolderPrefix: \"db.\",\n  databotFolderName: \"databots\",\n\n  databotHostFolderPrefix: \"dh.\",\n  databotHostFolderName: \"databot hosts\",\n\n  identityFilterPlaceholder: \"@@_identity_@@\",\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/constants.js\n// module id = 0\n// module chunks = 0","module.exports = __WEBPACK_EXTERNAL_MODULE_1__;\n\n\n//////////////////\n// WEBPACK FOOTER\n// external {\"commonjs\":\"lodash\",\"commonjs2\":\"lodash\",\"amd\":\"_\",\"root\":\"_\"}\n// module id = 1\n// module chunks = 0","(function() {\n    var exLog = console.log;\n    console.log = function(msg) {\n        exLog.apply(this, arguments);\n        alert(msg);\n    }\n})();\n\nexport default console.log;\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/debug.js\n// module id = 2\n// module chunks = 0","import errLog from \"./debug\";\nimport parser from \"mongo-parse\";\nimport _ from \"lodash\";\n\n/*\n  * Extract a dictionary of values from params corresponding to the given array of field paths,\n  * where paths use the dot notation, e.g. address.postcode.\n  */\nconst buildDataKey = function(fieldPaths, params) {\n  const _ = require(\"lodash\");\n\n  const keys = {};\n  _.forEach(fieldPaths, function(f) {\n    // Get the field path.\n    const key = f.asc || f.desc;\n    const pointers = parser.DotNotationPointers(params, key);\n    if (pointers.length === 0 || typeof pointers[0].val === \"undefined\") {\n      errLog(\"no key data for field '%s' in %j\", key, params);\n    } else {\n      keys[key] = pointers[0].val;\n    }\n  });\n\n  return keys;\n}\n\nexport default buildDataKey;\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/build-data-key.js\n// module id = 3\n// module chunks = 0","import constants from \"./constants\";\n\nconst isDatabotInstanceRunning = function(databotInstance) {\n  return databotInstance && (\n    databotInstance.status === constants.runningDatabotStatus || \n    databotInstance.status === constants.installingDatabotStatus || \n    databotInstance.status === constants.partRunningDatabotStatus ||\n    databotInstance.status === constants.pausedDatabotStatus\n  );\n};\n\nexport default {\n  isDatabotInstanceRunning: isDatabotInstanceRunning\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/databot-utils.js\n// module id = 4\n// module chunks = 0","const flattenJSON = function(data) {\n  const result = {};\n  function recurse (cur, prop) {\n    if (Object(cur) !== cur) {\n      result[prop] = cur;\n    } else if (Array.isArray(cur)) {\n      const l = cur.length;\n      for(let i = 0; i < l; i++) {\n        recurse(cur[i], prop + \".\" + i);\n      }\n      if (l === 0)\n        result[prop] = [];\n    } else {\n      let isEmpty = true;\n      for (let p in cur) {\n        isEmpty = false;\n        recurse(cur[p], prop ? prop+\".\"+p : p);\n      }\n      if (isEmpty && prop)\n        result[prop] = {};\n    }\n  }\n  recurse(data, \"\");\n  return result;\n};\n  \nexport default flattenJSON;\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/flatten.js\n// module id = 5\n// module chunks = 0","import constants from \"./constants\";\n\nconst isResourceType = function(resource, type) {\n  return (\n    resource.schemaDefinition ?\n    (resource.schemaDefinition.id === type || (resource.schemaDefinition.basedOn && resource.schemaDefinition.basedOn.indexOf(type) >= 0)) :\n    resource.baseType === type\n  );\n};\n\nconst getResourceTypeText = function(type) {\n  let text;\n  switch (type) {\n    case constants.groupResourceType:\n      text = \"folder\";\n      break;\n    case constants.rawFileResourceType:\n      text = \"raw file\";\n      break;\n    case constants.widgetVisualisationResourceType:\n      text = \"widget visualisation\";\n      break;\n    case constants.timeSeriesVisualisationResourceType:\n      text = \"time series visualisation\";\n      break;\n    case constants.mapVisualisationResourceType:\n      text = \"map visualisation\";\n      break;\n    case constants.statusVisualisationResourceType:\n      text = \"status visualisation\";\n      break;\n    case constants.scheduledTasksResourceType:\n      text = \"scheduled tasks\";\n      break;\n    case constants.processHostsResourceType:\n      text = \"process hosts\";\n      break;\n    default:\n      // Most single word resource types are OK.\n      text = type;\n      break;        \n  }\n  return text;\n};\n\nexport default {\n  isResourceType: isResourceType,\n  getResourceTypeText: getResourceTypeText\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/resource-utils.js\n// module id = 6\n// module chunks = 0","import Promise from \"bluebird\";\nimport _ from \"lodash\";\nimport errLog from \"./debug\";\nimport constants from \"./constants\";\n\n// From mongoose/lib/schema.js\nconst reservedFieldNames = [\n  \"_id\",              // <---- TDX specific\n  \"prototype\",\n  // EventEmitter\n  \"emit\",\n  \"on\",\n  \"once\",\n  \"listeners\",\n  \"removeListener\",\n  // document properties and functions\n  \"collection\",\n  \"db\",\n  \"errors\",\n  \"init\",\n  \"isModified\",\n  \"isNew\",\n  \"get\",\n  \"modelName\",\n  \"save\",\n  \"schema\",\n  \"set\",\n  \"toObject\",\n  \"validate\",\n  \"remove\",\n  // hooks.js\n  \"_pres\",\n  \"_posts\"\n];\n\n// Convert from simple array list to TDX index format.\n// Assume ascending sort direction.\n// e.g. [\"id\", \"code\"] => [{asc: \"id\"}, {asc: \"code\"}]\n//\n// Will also convert from mongoose index spec to tdx format.\n// e.g. {id: 1, code: -1} => [{asc: \"id\"}, {desc: \"code\"}]\n//\nconst indexToTDX = function(indexFields, errList) {\n  const tdxIndex = [];\n\n  if (Array.isArray(indexFields)) {\n    _.forEach(indexFields, function(fieldSpec, idx) {\n      if (typeof fieldSpec === \"string\") {\n        tdxIndex.push({\"asc\": fieldSpec});\n      } else if (fieldSpec.asc || fieldSpec.desc) {\n        tdxIndex.push(fieldSpec);\n      } else {\n        errList.push(\"invalid index spec: \" + JSON.stringify(fieldSpec));          \n      }\n    });\n  } else if (typeof indexFields === \"object\") {\n    _.forEach(indexFields, function(sortDirection, key) {\n      if (sortDirection === -1) {\n        tdxIndex.push({desc: key});\n      } else {\n        tdxIndex.push({asc: key});\n      }\n    });\n  }\n\n  return tdxIndex;\n};\n\nconst validateTDXType = function(type, errList) {\n  let properType;\n  type = type.toLowerCase();\n  if (!constants.mongooseTypes[type]) {\n    errList.push(\"invalid base type: \" + type);\n  } else {\n    properType = type;\n  }\n  return properType;\n};\n\n// Converts a schema from mongoose to TDX format.\nconst schemaToTDX = function(schema, errList) {\n  if (typeof schema === \"object\") {    \n    _.forEach(schema, function(value, key) {\n      if (key === \"__tdxType\") {\n        // Ensure array type list.\n        schema[key] = [].concat(value);\n      } else if (key === \"__tdxRequired\" || key === \"__tdxDefault\" || key === \"__tdxDescription\") {\n        // Do nothing.\n      } else if (Array.isArray(value)) {\n        if (value.length === 1) {\n          value[0] = schemaToTDX(value[0], errList);\n        } else {\n          // Assume a 'mixed' mongoose type.\n          schema[key] = [];\n        }\n      } else if (typeof value === \"object\") {\n        // Recurse for sub-documents\n        schema[key] = schemaToTDX(value, errList);\n      } else if (key === \"type\" && typeof value === \"string\") {\n        // A mongoose-style {type: \"String\"} specification.\n        // Convert to TDX format.\n        schema.__tdxType = [validateTDXType(value, errList)];\n        delete schema.type;\n      } else if (typeof value === \"string\") {\n        schema[key] = {__tdxType: [validateTDXType(value, errList)]};\n      } else {\n        errList.push(\"invalid schema definition, unexpected: \" + schema);\n      }\n    });\n\n    return schema;\n  } else if (typeof schema === \"string\") {\n    return {__tdxType: [validateTDXType(schema, errList)]};\n  } else {\n    errList.push(\"invalid schema definition, unexpected: \" + schema);\n  }\n};\n\nconst validateMongooseType = function(type, errList) {\n  let properType;\n  type = type.toLowerCase();\n  if (!constants.mongooseTypes[type]) {\n    errList.push(\"invalid base type: \" + type);\n  } else {\n    properType = _.capitalize(type);\n  }\n  return properType;\n};\n\nconst schemaToMongoose = function(schema, errList) {\n  errList = errList || [];\n\n  _.each(schema, function(v, k) {\n    if (reservedFieldNames.indexOf(k) >= 0) {\n      errLog(\"invalid field name (reserved): %s\", k);\n      errList.push(\"invalid field name (reserved): \" + k);\n    } else if (k === \"__tdxRequired\") {\n      schema.required = schema.__tdxRequired;\n      delete schema.__tdxRequired;\n    } else if (k === \"__tdxDefault\") {\n      schema.default = schema.__tdxDefault;\n      delete schema.__tdxDefault;\n    } else if (k === \"__tdxDescription\") {\n      // Remove this as it's TDX documentation.\n      delete schema.__tdxDescription;\n    } else if (k === \"__tdxType\") {\n      // This is an explicit type specification,  e.g. { __tdxType: [\"string\",\"geographic\",\"address\",\"postcode\"]}\n      if (!v) {\n        errLog(\"unexpected __tdxType value: %j\", v);\n        errList.push(\"missing __tdxType\");\n      } else {\n        // Ensure type is an array.\n        v = [].concat(v);\n        delete schema.__tdxType;\n        // The base type is the first element and should be a valid mongoose type\n        schema.type = v[0].toLowerCase();\n        if (schema.type === \"object\") {\n          schema = {};\n        } else if (schema.type === \"array\") {\n          schema = [];\n        } else {\n          schema.type = validateMongooseType(schema.type, errList);\n        }\n      }\n    } else if (Array.isArray(v)) {\n      // Array\n      if (v.length > 1) {\n        errList.push(\"invalid array type specification for key: \" + k);\n      } else if (v.length > 0) {\n        if (typeof v[0] === \"string\") {\n          schema[k] = {type: validateMongooseType(v[0], errList)};\n        } else {\n          schema[k] = [schemaToMongoose(v[0], errList)];\n        }\n      }\n    } else if (typeof v === \"object\") {\n      // Sub-document\n      schema[k] = schemaToMongoose(v, errList);\n    } else if (typeof v !== \"string\") {\n      // TODO - review\n      // Don't treat this as an error, just ignore.\n      // Seems to be caused be some legacy schema definitions with { default: true, required: true } etc.\n      // errList.push(\"invalid schema definition - unexpected type for key '\" + k + \"': \" + (typeof v));\n      errLog(\"invalid schema definition - unexpected type for key '\" + k + \"': \" + (typeof v));\n      delete schema[k];\n    } else {\n      schema[k] = {type: validateMongooseType(v, errList)};\n    }\n  });\n\n  return schema;\n};\n\nconst definitionToMongoose = function(name, tdxSchema) {\n  const uniqueIndex = tdxSchema.uniqueIndex;\n  const indexes = tdxSchema.nonUniqueIndexes;\n\n  // Convert any given indexes to mongodb format \n  //\n  // Because these dynamic schema definitions are stored in mongodb as documents,\n  // we have to store them in a backwards fashion as mongodb does not allow\n  // key names to contain periods. For example, if the index was saved\n  // as { \"address.postcode\": 1 } mongodb would complain about \"address.postcode\".\n  //     \n  // So we store indexes (which are likely to contain dots e.g. if indexing\n  // on nested document) in the form:\n  //\n  // { \"asc\": \"my.nested.key\" } or { \"desc\": \"address.postcode\" }\n  //q\n  // Here we convert this stored format to mongodb format so the index can be created.\n  // \n  // The 'indexes' parameter should be an array of arrays of index specifiers, e.g.\n  // the following specifies two indexes, one is a compound index on account and order,\n  // the other is an individual index on completedAt:\n  //\n  // [ [ { \"asc\": \"account\" }, { \"asc\": \"order\" } ], [ {\"asc\": \"completedAt\" } ] ]\n  //\n  // this should translate to a single array of objects, e.g.:\n  //\n  // [ { account: 1 , order: 1 }, { completedAt: 1} ]\n  //\n  const nonUniqueIndexes = [];\n  _.forEach(indexes, function(nonUniqueIndex) {\n    if (nonUniqueIndex.length > 0) {\n      const index = {};\n      _.forEach(nonUniqueIndex, function(i) {\n        index[i.asc || i.desc] = (i.asc ? 1 : -1);\n      });\n      nonUniqueIndexes.push(index);        \n    }\n  });\n  log(\"translated non unique indexes for %s from %j to %j\", name, indexes, nonUniqueIndexes);\n\n  // Do the same for the unique index.\n  // Use the 'uniqueIndex' parameter to set the PK of the schema.\n  // Do this rather than use the built-in mongoose specification in order\n  // to support compound indexes, where the order of fields is important.\n  //\n  // See comment above for index format explanation.\n  const primaryIndex = {};\n  _.forEach(uniqueIndex, function(i) {\n    primaryIndex[i.asc || i.desc] = (i.asc ? 1 : -1);\n  });\n  log(\"translated primary index for %s from %j to %j\", name, uniqueIndex, primaryIndex);\n      \n  //\n  // Remove all index information from the schema, as we set the indexes\n  // manually below.\n  //        \n  log(\"transforming schema for %s: %j\", tdxSchema.id, tdxSchema.dataSchema);\n  const errList = [];\n  const mongooseSchema = schemaToMongoose(tdxSchema.dataSchema, errList);\n  if (errList.length) {\n    throw new Error(\"invalid mongoose schema: \" + errList.join(\",\"));\n  }\n\n  log(\"schema transformed to %j\", mongooseSchema);\n\n  return {\n    schema: mongooseSchema,\n    uniqueIndex: primaryIndex,\n    nonUniqueIndexes: nonUniqueIndexes\n  };\n}\n\nexport default {\n  definitionToMongoose: definitionToMongoose,\n  schemaToMongoose: function(tdxSchema, errList) {\n    return schemaToMongoose(_.cloneDeep(tdxSchema), errList);\n  },\n  schemaToTDX: function(mongooseSchema, errList) {\n    return schemaToTDX(_.cloneDeep(mongooseSchema), errList);\n  },\n  indexToTDX: indexToTDX\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/schema-utils.js\n// module id = 7\n// module chunks = 0","\n/*\n\tshorthash\n\t(c) 2013 Bibig\n\t\n\thttps://github.com/bibig/node-shorthash\n\tshorthash may be freely distributed under the MIT license.\n*/\n\n// refer to: http://werxltd.com/wp/2010/05/13/javascript-implementation-of-javas-string-hashcode-method/\nfunction bitwise(str){\n\tvar hash = 0;\n\tif (str.length == 0) return hash;\n\tfor (var i = 0; i < str.length; i++) {\n\t\tvar ch = str.charCodeAt(i);\n\t\thash = ((hash<<5)-hash) + ch;\n\t\thash = hash & hash; // Convert to 32bit integer\n\t}\n\treturn hash;\n}\n\n// 10进制转化成62进制以内的进制\n// convert 10 binary to customized binary, max is 62\nfunction binaryTransfer(integer, binary) {\n\tbinary = binary || 62;\n\tvar stack = [];\n\tvar num;\n\tvar result = '';\n\tvar sign = integer < 0 ? '-' : '';\n\t\n\tfunction table (num) {\n\t\tvar t = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ';\n\t\treturn t[num];\n\t}\n\t\n\tinteger = Math.abs(integer);\n\t\n\twhile (integer >= binary) {\n\t\tnum = integer % binary;\n\t\tinteger = Math.floor(integer / binary);\n\t\tstack.push(table(num));\n\t}\n\t\n\tif (integer > 0) {\n\t\tstack.push(table(integer));\n\t}\n\t\n\tfor (var i = stack.length - 1; i >= 0; i--) {\n\t\tresult += stack[i];\n\t} \n\t\n\treturn sign + result;\n}\n\n\n/**\n * why choose 61 binary, because we need the last element char to replace the minus sign\n * eg: -aGtzd will be ZaGtzd\n */\nfunction unique (text) {\n\tvar id = binaryTransfer(bitwise(text), 61);\n\treturn id.replace('-', 'Z');\n}\n\nexport default {\n  bitwise,\n  binaryTransfer,\n  unique\n};\n\n\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/short-hash.js\n// module id = 8\n// module chunks = 0","import resourceUtils from \"./resource-utils\";\nimport databotUtils from \"./databot-utils\";\nimport schemaUtils from \"./schema-utils\";\nimport flattenJSON from \"./flatten\";\nimport buildDataKey from \"./build-data-key\";\nimport shortHash from \"./short-hash\";\n\nconst isEmailValid = function(address) { \n  // TODO - improve this (use mailgun?)\n  return /^[A-Z0-9'.1234z_%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,4}$/i.test(address);\n};\n\nconst isHostNameValid = function(hostname) {\n  // From http://stackoverflow.com/a/106223\n  return /^(([a-zA-Z0-9]|[a-zA-Z0-9][a-zA-Z0-9\\-]*[a-zA-Z0-9])\\.)*([A-Za-z0-9]|[A-Za-z0-9][A-Za-z0-9\\-]*[A-Za-z0-9])$/.test(hostname);\n};\n\nconst isDateValid = function(d) {\n  // From http://stackoverflow.com/q/1353684 \n  if (Object.prototype.toString.call(d) !== \"[object Date]\")\n    return false;\n  return !isNaN(d.getTime());\n}\n\nconst isNumeric = function (n) { return !isNaN(parseFloat(n)) && isFinite(n); };\n\nconst makeTDXAccount = function(email, tdx) {\n  /*\n    * tdx accounts are stored in email/hostname format, e.g. toby.ealden@gmail.com/tdx.nqminds.com\n    */\n  return email + \"/\" + tdx;\n};\n\nconst splitTDXAccount = function(username) {\n  /*\n    * tdx accounts are stored in email/hostname format, e.g. toby.ealden@gmail.com/tdx.nqminds.com\n    */\n  let result;\n  const split = username.toLowerCase().split(\"/\");\n  if (split.length === 2 && isEmailValid(split[0]) && (isHostNameValid(split[1]) || split[1].indexOf(\"localhost:\") === 0)) {\n    result = {\n      email: split[0],\n      tdx: split[1]\n    };\n  }\n  return result;\n};\n\nconst parseFunction = function(funcText) {\n  const funcReg = /function *\\(([^()]*)\\)[ \\n\\t]*{(.*)}/gmi;\n  const match = funcReg.exec(funcText.replace(/\\n/g, \" \"));\n\n  if (match) {\n    return new Function(match[1].split(\",\"), match[2]);\n  }\n\n  return null;\n};\n  \nexport default {\n  resourceUtils,\n  databotUtils,\n  schemaUtils,\n  flattenJSON,\n  buildDataKey,\n  shortHash,\n  isEmailValid,\n  isDateValid,\n  isHostNameValid,\n  isNumeric,\n  makeTDXAccount,\n  splitTDXAccount,\n  parseFunction,\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/index.js\n// module id = 9\n// module chunks = 0","module.exports = __WEBPACK_EXTERNAL_MODULE_10__;\n\n\n//////////////////\n// WEBPACK FOOTER\n// external \"bluebird\"\n// module id = 10\n// module chunks = 0","module.exports = __WEBPACK_EXTERNAL_MODULE_11__;\n\n\n//////////////////\n// WEBPACK FOOTER\n// external \"mongo-parse\"\n// module id = 11\n// module chunks = 0"],"sourceRoot":""}